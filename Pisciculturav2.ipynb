{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WANGER~1\\AppData\\Local\\Temp/ipykernel_8956/4080736814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_timestamp(df):\n",
    "    dia = []\n",
    "    mes = []\n",
    "    ano = []\n",
    "    hora = []\n",
    "    minuto = []\n",
    "    segundo = []\n",
    "\n",
    "    for d, h in zip(df.Data, df.Hora):\n",
    "        dia.append(int(d[:2]))\n",
    "        mes.append(int(d[3:5]))\n",
    "        ano.append(int(d[6:]))\n",
    "    \n",
    "        hora.append(int(h[:2]))\n",
    "        minuto.append(int(h[3:5]))\n",
    "        segundo.append(int(h[6:]))\n",
    "\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame({'year': ano,\n",
    "                   'month': mes,\n",
    "                   'day': dia,\n",
    "                   'hour': hora,\n",
    "                   'minute': minuto,\n",
    "                   'second': segundo})\n",
    "    index = pd.to_datetime(data)\n",
    "\n",
    "    df['timer'] = index\n",
    "    df = df.drop_duplicates(subset=['timer'])\n",
    "    df.index = df['timer']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df, frequency = '30min'):    \n",
    "    columns = ['Temp', 'OD', 'PH', 'NH3', 'AT']\n",
    "    data = pd.DataFrame()    \n",
    "    for c in columns:\n",
    "        group = df.groupby([pd.Grouper(freq=frequency), 'link'], sort=False)[c].mean().unstack().reset_index(\n",
    "                        ).set_index('timer').resample(frequency).mean().transform(\n",
    "                        lambda x: x.fillna(method='ffill')).transform(\n",
    "                        lambda x: x.fillna(method='backfill')).transform(\n",
    "                        lambda x: x.fillna(method='pad')).dropna()\n",
    "        \n",
    "        col = group.values.reshape(1,-1)\n",
    "        data[c] = col[0]\n",
    "    \n",
    "    data.index = group.index\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_std(df, frequency = '30min'):    \n",
    "    columns = ['Temp', 'OD', 'PH', 'NH3', 'AT']\n",
    "    data = pd.DataFrame()    \n",
    "    for c in columns:\n",
    "        group = df.groupby([pd.Grouper(freq=frequency), 'link'], sort=False)[c].std()\n",
    "        \n",
    "        col = group.values.reshape(1,-1)\n",
    "        data[c] = col[0]\n",
    "    \n",
    "    data.index = group.index\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_column(dataset, frequency, column):\n",
    "    dataset = dataset.groupby([pd.Grouper(freq=frequency)], sort=False)[column]\n",
    "\n",
    "    lista = list(dataset)\n",
    "    dictionary = {}\n",
    "    for k, v in lista:  \n",
    "        dictionary[str(k)] = v\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_group(dictionary, arg, minute):\n",
    "#     for k in dictionary:\n",
    "#         if pd.Timestamp(k) <= arg < pd.Timestamp(k) + pd.Timedelta(minutes=minute):    \n",
    "#             break\n",
    "#     return dictionary[k]\n",
    "def get_group(dictionary, arg, minute):\n",
    "    keys = []\n",
    "    for k in dictionary:\n",
    "        if arg <= pd.Timestamp(k) < arg + pd.Timedelta(minutes=minute):    \n",
    "            keys.append(k)\n",
    "        \n",
    "        if not (arg <= pd.Timestamp(k) < arg + pd.Timedelta(minutes=minute)) and len(keys) > 0:\n",
    "            break\n",
    "    \n",
    "    values = []\n",
    "    import numpy as np\n",
    "    for k in keys:\n",
    "        values = np.concatenate([values, dictionary[k]])\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_G(dictionary, arg, minute):\n",
    "    keys = []\n",
    "    for k in dictionary:\n",
    "        if pd.Timestamp(k) <= arg < pd.Timestamp(k) + pd.Timedelta(minutes=minute):    \n",
    "            keys.append(k)\n",
    "        \n",
    "        if not (pd.Timestamp(k) <= arg < pd.Timestamp(k) + pd.Timedelta(minutes=minute)) and len(keys) > 0:\n",
    "            break\n",
    "    \n",
    "    values = []\n",
    "    import numpy as np\n",
    "    for k in keys:\n",
    "        values = np.concatenate([values, dictionary[k]])\n",
    "    return np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, p):\n",
    "    X = df.drop([\"y\"], axis=1)\n",
    "    y = df.y\n",
    "\n",
    "    n = int(X.shape[0]*p)\n",
    "\n",
    "    X_train = X[0:n]\n",
    "    y_train = y[0:n]\n",
    "\n",
    "    X_test = X[n:]\n",
    "    y_test = y[n:]\n",
    "\n",
    "    X = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    return X, X_test, y, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(X, X_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):    \n",
    "    import numpy as np\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_val, y_pred):\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "    MAE = mae(y_val, y_pred)\n",
    "    MSE = mse(y_val, y_pred)\n",
    "    RMSE = mse(y_val, y_pred, squared=False)  \n",
    "    MAPE = mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "    return {\"MAE\": MAE, \"MSE\": MSE, \"RMSE\": RMSE, \"MAPE\": MAPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_all(df, n, y):\n",
    "    cols = list(df.columns)*n\n",
    "    cols.append(y)\n",
    "\n",
    "    df_new = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for i in range(0, df.shape[0]-n):\n",
    "        lista = []\n",
    "\n",
    "        for j in range(i, i+n):\n",
    "            lista.append(df.loc[[j]].reset_index(drop=True))\n",
    "\n",
    "        lista.append(df.loc[[i+n]][y].reset_index(drop=True))  \n",
    "        df_new = df_new.append(pd.concat(lista, axis=1), ignore_index=True)    \n",
    "\n",
    "    cols = ['C'+str(i) for i in range(len(cols)-1)]\n",
    "    cols.append('y')\n",
    "    df_new.columns = cols  \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = pd.read_csv('dadosfisicosquimicos.csv', sep=';')\n",
    "df_start = df_start.drop(['Unnamed: 7'], axis=1)\n",
    "df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df_start.Temp, color='#069AF3', label='Temperatura')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Grau Celsius')\n",
    "plt.title('Coleta sensorial da temperatura')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df_start.OD, color='#069AF3', label='Oxigênio dissolvido')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('mg/l')\n",
    "plt.title('Coleta sensorial do OD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df_start.PH, color='#069AF3', label='Potencial hidrogeniônico')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('pH')\n",
    "plt.title('Coleta sensorial do pH')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start['link'] = ['x']*df_start.shape[0]\n",
    "df_start = set_timestamp(df_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = group_by_std(df_start, '30min')\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [df_std.Temp, df_std.OD, df_std.PH]\n",
    "labels = ['Temperatura', 'OD', 'pH']\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "\n",
    "bplot = ax.boxplot(data, patch_artist=True, labels= labels, widths=0.45, medianprops={\"linewidth\": 2})\n",
    "\n",
    "\n",
    "# fill with colors\n",
    "colors = ['pink', 'lightblue', 'lightgreen']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# adding horizontal grid lines\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xlabel('Sensor')\n",
    "ax.set_ylabel('Desvio padrão')\n",
    "plt.title('Desvio padrão resultante do agrupamento de 30 minutos.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = group_data(df_start)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df.Temp, color='#069AF3', label='Temperatura')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Grau Celsius')\n",
    "plt.title('Coleta sensorial da temperatura')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df.OD, color='#069AF3', label='Oxigênio dissolvido')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('mg/l')\n",
    "plt.title('Coleta sensorial do OD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.plot(df.PH, color='#069AF3', label='Potencial hidrogeniônico')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('pH')\n",
    "plt.title('Coleta sensorial do pH')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_40 = group_column(df_start, '40min', 'OD')\n",
    "OD_50 = group_column(df_start, '50min', 'OD')\n",
    "OD_60 = group_column(df_start, '60min', 'OD')\n",
    "\n",
    "PH_40 = group_column(df_start, '40min', 'PH')\n",
    "PH_50 = group_column(df_start, '50min', 'PH')\n",
    "PH_60 = group_column(df_start, '60min', 'PH')\n",
    "\n",
    "Temp_40 = group_column(df_start, '40min', 'Temp')\n",
    "Temp_50 = group_column(df_start, '50min', 'Temp')\n",
    "Temp_60 = group_column(df_start, '60min', 'Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(columns=['OD_40', 'OD_50', 'OD_60',\n",
    "                            'PH_40', 'PH_50', 'PH_60',\n",
    "                            'TEMP_40', 'TEMP_50', 'TEMP_60'])\n",
    "\n",
    "for value, idx in zip(df.index, range(df.shape[0])):\n",
    "\n",
    "    ODm_40 = get_group_G(OD_40, value, 40)\n",
    "    ODm_50 = get_group_G(OD_50, value, 50)\n",
    "    ODm_60 = get_group_G(OD_60, value, 60)\n",
    "\n",
    "    PHm_40 = get_group_G(PH_40, value, 40)\n",
    "    PHm_50 = get_group_G(PH_50, value, 50)\n",
    "    PHm_60 = get_group_G(PH_60, value, 60)\n",
    "\n",
    "    Tempm_40 = get_group_G(Temp_40, value, 40)\n",
    "    Tempm_50 = get_group_G(Temp_50, value, 50)\n",
    "    Tempm_60 = get_group_G(Temp_60, value, 60)\n",
    "    \n",
    "    new.loc[idx] = [\n",
    "                    ODm_40, ODm_50, ODm_60,\n",
    "                    PHm_40, PHm_50, PHm_60,\n",
    "                    Tempm_40, Tempm_50, Tempm_60\n",
    "                   ]\n",
    "\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedData = df.reset_index(drop=True)\n",
    "new = new.reset_index(drop=True)\n",
    "\n",
    "result = pd.concat([groupedData, new], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('dataset_preprocessado.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(feature):\n",
    "    column = [feature]\n",
    "    column_y = feature\n",
    "    window = 1\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    shift_prediction *= -1\n",
    "    X = data.drop(['y'], axis=1)\n",
    "    y = data['y'].shift(periods=shift_prediction)\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data[:shift_prediction]\n",
    "    data = data.astype('float64')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "    \n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_error(feature):\n",
    "    column = [feature]\n",
    "    column_y = feature\n",
    "    window = 1\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    shift_prediction *= -1\n",
    "    X = data.drop(['y'], axis=1)\n",
    "    y = data['y'].shift(periods=shift_prediction)\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data[:shift_prediction]\n",
    "    data = data.astype('float64')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "    \n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_neuronios(feature, saida):\n",
    "    column = [feature]\n",
    "    column_y = feature\n",
    "    window = 1\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    shift_prediction *= -1\n",
    "    X = data.drop(['y'], axis=1)\n",
    "    y = data['y'].shift(periods=shift_prediction)\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data[:shift_prediction]\n",
    "    data = data.astype('float64')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "    \n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    \n",
    "    df_saida = pd.DataFrame(columns=[\"neurons\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "    df_saida.to_csv(saida, mode='a')\n",
    "\n",
    "    \n",
    "    for n in range(20,220, 20):\n",
    "        \n",
    "        df_saida = pd.DataFrame(columns=[\"neurons\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "        \n",
    "        for i in range(1, 101):\n",
    "            model = MLPRegressor(hidden_layer_sizes=(n), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            M = metrics(y_test.values, y_pred)\n",
    "            M['neurons'] = n\n",
    "            M['itaration'] = i\n",
    "            df_saida = df_saida.append(M, ignore_index=True)\n",
    "    \n",
    "        df_saida.to_csv(saida, mode='a', header=False)\n",
    "    \n",
    "    return df_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_camadas(feature, neuronios, saida):\n",
    "    column = [feature]\n",
    "    column_y = feature\n",
    "    window = 1\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    shift_prediction *= -1\n",
    "    X = data.drop(['y'], axis=1)\n",
    "    y = data['y'].shift(periods=shift_prediction)\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data[:shift_prediction]\n",
    "    data = data.astype('float64')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "    \n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    \n",
    "    df_saida = pd.DataFrame(columns=[\"layers\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "    df_saida.to_csv(saida, mode='a')\n",
    "\n",
    "    neurons = []\n",
    "    \n",
    "    for n in range(2,6):\n",
    "        \n",
    "        df_saida = pd.DataFrame(columns=[\"layers\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "        neurons.append(neuronios)\n",
    "        \n",
    "        for i in range(1, 101):\n",
    "            model = MLPRegressor(hidden_layer_sizes=tuple(neurons), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            M = metrics(y_test.values, y_pred)\n",
    "            M['layers'] = n\n",
    "            M['itaration'] = i\n",
    "            df_saida = df_saida.append(M, ignore_index=True)\n",
    "    \n",
    "        df_saida.to_csv(saida, mode='a', header=False)\n",
    "    \n",
    "    return df_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_features(features, y, neuronios, saida):\n",
    "    column = []\n",
    "    column_y = y\n",
    "    window = 1\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    df_saida = pd.DataFrame(columns=[\"n_features\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "    df_saida.to_csv(saida, mode='a')\n",
    "        \n",
    "    for c in features:\n",
    "        column.append(c)\n",
    "        data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "        data = data.dropna()\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        shift_prediction = 6\n",
    "        shift_prediction *= -1\n",
    "        X = data.drop(['y'], axis=1)\n",
    "        y = data['y'].shift(periods=shift_prediction)\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        data = data[:shift_prediction]\n",
    "        data = data.astype('float64')\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "            \n",
    "        \n",
    "        df_saida = pd.DataFrame(columns=[\"n_features\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "        \n",
    "        for i in range(1, 101):\n",
    "            model = MLPRegressor(hidden_layer_sizes=neuronios, max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            M = metrics(y_test.values, y_pred)\n",
    "            M['n_features'] = len(column)\n",
    "            M['itaration'] = i\n",
    "            df_saida = df_saida.append(M, ignore_index=True)\n",
    "    \n",
    "        df_saida.to_csv(saida, mode='a', header=False)\n",
    "    \n",
    "    return df_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_janelas(features, y, neuronios, saida):\n",
    "    column = features\n",
    "    column_y = y\n",
    "    train_size = 0.7\n",
    "    shift_prediction = 6\n",
    "    \n",
    "    df_saida = pd.DataFrame(columns=[\"windows\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "    df_saida.to_csv(saida, mode='a')\n",
    "        \n",
    "    for window in range(1,6):\n",
    "        \n",
    "        data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "        data = data.dropna()\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        shift_prediction = 6\n",
    "        shift_prediction *= -1\n",
    "        X = data.drop(['y'], axis=1)\n",
    "        y = data['y'].shift(periods=shift_prediction)\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        data = data[:shift_prediction]\n",
    "        data = data.astype('float64')\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "            \n",
    "        \n",
    "        df_saida = pd.DataFrame(columns=[\"windows\", \"itaration\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\"])\n",
    "        \n",
    "        for i in range(1, 101):\n",
    "            model = MLPRegressor(hidden_layer_sizes=neuronios, max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            M = metrics(y_test.values, y_pred)\n",
    "            M['windows'] = window\n",
    "            M['itaration'] = i\n",
    "            df_saida = df_saida.append(M, ignore_index=True)\n",
    "    \n",
    "        df_saida.to_csv(saida, mode='a', header=False)\n",
    "    \n",
    "    return df_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_neuronios(arquivo):\n",
    "    df = pd.read_csv(arquivo)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    M_MAE = []\n",
    "    S_MAE = []\n",
    "\n",
    "    M_RMSE = []\n",
    "    S_RMSE = []\n",
    "\n",
    "    M_MAPE = []\n",
    "    S_MAPE = []\n",
    "    \n",
    "    for n in range(20,220,20):\n",
    "        \n",
    "        lista = df.loc[df.neurons == n]\n",
    "    \n",
    "        M_MAE.append(lista.MAE.mean())\n",
    "        S_MAE.append(lista.MAE.std())\n",
    "    \n",
    "        M_RMSE.append(lista.RMSE.mean())\n",
    "        S_RMSE.append(lista.RMSE.std())\n",
    "    \n",
    "        M_MAPE.append(lista.MAPE.mean())\n",
    "        S_MAPE.append(lista.MAPE.std())\n",
    "    \n",
    "    import numpy as np\n",
    "    M_MAE = np.array(M_MAE)\n",
    "    S_MAE = np.array(S_MAE)\n",
    "\n",
    "    M_RMSE = np.array(M_RMSE)\n",
    "    S_RMSE = np.array(S_RMSE)\n",
    "\n",
    "    M_MAPE = np.array(M_MAPE)\n",
    "    S_MAPE = np.array(S_MAPE)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = list(range(20,220,20))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "    plt.plot(X, M_RMSE, color='purple', marker='o', markersize=5, label='RMSE')\n",
    "    plt.fill_between(X, M_RMSE + S_RMSE, M_RMSE - S_RMSE, alpha=0.15, color='purple')\n",
    "\n",
    "    plt.plot(X, M_MAE, color='green', marker='o', markersize=5, label='MAE')\n",
    "    plt.fill_between(X, M_MAE + S_MAE, M_MAE - S_MAE, alpha=0.15, color='green')\n",
    "\n",
    "    plt.plot(X, M_MAPE, color='gold', marker='o', markersize=5, label='MAPE')\n",
    "    plt.fill_between(X, M_MAPE + S_MAPE, M_MAPE - S_MAPE, alpha=0.15, color='gold')\n",
    "    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(\"Erro médio dos 100 treinamentos de cada arquitetura MLP\", fontsize=18)\n",
    "    plt.xlabel('Número de neurônios', fontsize=18)\n",
    "    plt.ylabel('Erro', fontsize=18)\n",
    "    plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_camadas(arquivo):\n",
    "    df = pd.read_csv(arquivo)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    M_MAE = []\n",
    "    S_MAE = []\n",
    "\n",
    "    M_RMSE = []\n",
    "    S_RMSE = []\n",
    "\n",
    "    M_MAPE = []\n",
    "    S_MAPE = []\n",
    "    \n",
    "    for n in range(2,6):\n",
    "        \n",
    "        lista = df.loc[df.layers == n]\n",
    "    \n",
    "        M_MAE.append(lista.MAE.mean())\n",
    "        S_MAE.append(lista.MAE.std())\n",
    "    \n",
    "        M_RMSE.append(lista.RMSE.mean())\n",
    "        S_RMSE.append(lista.RMSE.std())\n",
    "    \n",
    "        M_MAPE.append(lista.MAPE.mean())\n",
    "        S_MAPE.append(lista.MAPE.std())\n",
    "    \n",
    "    import numpy as np\n",
    "    M_MAE = np.array(M_MAE)\n",
    "    S_MAE = np.array(S_MAE)\n",
    "\n",
    "    M_RMSE = np.array(M_RMSE)\n",
    "    S_RMSE = np.array(S_RMSE)\n",
    "\n",
    "    M_MAPE = np.array(M_MAPE)\n",
    "    S_MAPE = np.array(S_MAPE)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = list(range(2,6))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "    plt.plot(X, M_RMSE, color='purple', marker='o', markersize=5, label='RMSE')\n",
    "    plt.fill_between(X, M_RMSE + S_RMSE, M_RMSE - S_RMSE, alpha=0.15, color='purple')\n",
    "\n",
    "    plt.plot(X, M_MAE, color='green', marker='o', markersize=5, label='MAE')\n",
    "    plt.fill_between(X, M_MAE + S_MAE, M_MAE - S_MAE, alpha=0.15, color='green')\n",
    "\n",
    "    plt.plot(X, M_MAPE, color='gold', marker='o', markersize=5, label='MAPE')\n",
    "    plt.fill_between(X, M_MAPE + S_MAPE, M_MAPE - S_MAPE, alpha=0.15, color='gold')\n",
    "    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(\"Erro médio dos 100 treinamentos de cada arquitetura MLP\", fontsize=18)\n",
    "    plt.xlabel('Número de neurônios', fontsize=18)\n",
    "    plt.ylabel('Erro', fontsize=18)\n",
    "    plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_derivacao(arquivo):\n",
    "    df = pd.read_csv(arquivo)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    M_MAE = []\n",
    "    S_MAE = []\n",
    "\n",
    "    M_RMSE = []\n",
    "    S_RMSE = []\n",
    "\n",
    "    M_MAPE = []\n",
    "    S_MAPE = []\n",
    "    \n",
    "    for n in range(1,5):\n",
    "        \n",
    "        lista = df.loc[df.n_features == n]\n",
    "    \n",
    "        M_MAE.append(lista.MAE.mean())\n",
    "        S_MAE.append(lista.MAE.std())\n",
    "    \n",
    "        M_RMSE.append(lista.RMSE.mean())\n",
    "        S_RMSE.append(lista.RMSE.std())\n",
    "    \n",
    "        M_MAPE.append(lista.MAPE.mean())\n",
    "        S_MAPE.append(lista.MAPE.std())\n",
    "    \n",
    "    import numpy as np\n",
    "    M_MAE = np.array(M_MAE)\n",
    "    S_MAE = np.array(S_MAE)\n",
    "\n",
    "    M_RMSE = np.array(M_RMSE)\n",
    "    S_RMSE = np.array(S_RMSE)\n",
    "\n",
    "    M_MAPE = np.array(M_MAPE)\n",
    "    S_MAPE = np.array(S_MAPE)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = list(range(1,5))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "    plt.plot(X, M_RMSE, color='purple', marker='o', markersize=5, label='RMSE')\n",
    "    plt.fill_between(X, M_RMSE + S_RMSE, M_RMSE - S_RMSE, alpha=0.15, color='purple')\n",
    "\n",
    "    plt.plot(X, M_MAE, color='green', marker='o', markersize=5, label='MAE')\n",
    "    plt.fill_between(X, M_MAE + S_MAE, M_MAE - S_MAE, alpha=0.15, color='green')\n",
    "\n",
    "    plt.plot(X, M_MAPE, color='gold', marker='o', markersize=5, label='MAPE')\n",
    "    plt.fill_between(X, M_MAPE + S_MAPE, M_MAPE - S_MAPE, alpha=0.15, color='gold')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(\"Erro médio dos 100 treinamentos de cada arquitetura MLP\", fontsize=18)\n",
    "    plt.xlabel('Número de neurônios', fontsize=18)\n",
    "    plt.ylabel('Erro', fontsize=18)\n",
    "    plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_janelas(arquivo):\n",
    "    df = pd.read_csv(arquivo)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    M_MAE = []\n",
    "    S_MAE = []\n",
    "\n",
    "    M_RMSE = []\n",
    "    S_RMSE = []\n",
    "\n",
    "    M_MAPE = []\n",
    "    S_MAPE = []\n",
    "    \n",
    "    for n in range(1,6):\n",
    "        \n",
    "        lista = df.loc[df.windows == n]\n",
    "    \n",
    "        M_MAE.append(lista.MAE.mean())\n",
    "        S_MAE.append(lista.MAE.std())\n",
    "    \n",
    "        M_RMSE.append(lista.RMSE.mean())\n",
    "        S_RMSE.append(lista.RMSE.std())\n",
    "    \n",
    "        M_MAPE.append(lista.MAPE.mean())\n",
    "        S_MAPE.append(lista.MAPE.std())\n",
    "    \n",
    "    import numpy as np\n",
    "    M_MAE = np.array(M_MAE)\n",
    "    S_MAE = np.array(S_MAE)\n",
    "\n",
    "    M_RMSE = np.array(M_RMSE)\n",
    "    S_RMSE = np.array(S_RMSE)\n",
    "\n",
    "    M_MAPE = np.array(M_MAPE)\n",
    "    S_MAPE = np.array(S_MAPE)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    X = list(range(1,6))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "    plt.plot(X, M_RMSE, color='purple', marker='o', markersize=5, label='RMSE')\n",
    "    plt.fill_between(X, M_RMSE + S_RMSE, M_RMSE - S_RMSE, alpha=0.15, color='purple')\n",
    "\n",
    "    plt.plot(X, M_MAE, color='green', marker='o', markersize=5, label='MAE')\n",
    "    plt.fill_between(X, M_MAE + S_MAE, M_MAE - S_MAE, alpha=0.15, color='green')\n",
    "\n",
    "    plt.plot(X, M_MAPE, color='gold', marker='o', markersize=5, label='MAPE')\n",
    "    plt.fill_between(X, M_MAPE + S_MAPE, M_MAPE - S_MAPE, alpha=0.15, color='gold')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(\"Erro médio dos 100 treinamentos de cada arquitetura MLP\", fontsize=18)\n",
    "    plt.xlabel('Número de neurônios', fontsize=18)\n",
    "    plt.ylabel('Erro', fontsize=18)\n",
    "    plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline('Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline('OD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline('PH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_neuronios('Temp', 'neuronios_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_neuronios('OD', 'neuronios_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_neuronios('PH', 'neuronios_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_neuronios('neuronios_Temp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_neuronios('neuronios_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_neuronios('neuronios_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_camadas('Temp', 140, 'camadas_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_camadas('OD', 180, 'camadas_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_camadas('PH', 180, 'camadas_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_camadas('camadas_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_camadas('camadas_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_camadas('camadas_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_features(['Temp', 'TEMP_40', 'TEMP_50', 'TEMP_60'], 'Temp', (180), 'derivacao_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_features(['OD', 'OD_40', 'OD_50', 'OD_60'], 'OD', (180,180,180,180,180), 'derivacao_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_features(['PH', 'PH_40', 'PH_50', 'PH_60'], 'PH', (180,180,180), 'derivacao_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_derivacao('derivacao_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_derivacao('derivacao_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_derivacao('derivacao_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_janelas(['Temp'], 'Temp', (180), 'janelas_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_janelas(['OD'], 'OD', (180,180,180,180,180), 'janelas_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_janelas(['PH', 'PH_40', 'PH_50', 'PH_60'], 'PH', (180,180,180), 'janelas_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_janelas('janelas_Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_janelas('janelas_OD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_janelas('janelas_PH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [dfbox.loc[dfbox.neurons == 20].RMSE, \n",
    "        dfbox.loc[dfbox.neurons == 40].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 60].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 80].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 100].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 120].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 140].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 160].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 180].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 200].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [dfbox.loc[dfbox.neurons == 20].MAE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAPE = [dfbox.loc[dfbox.neurons == 20].MAPE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAPE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAPE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [dfbox.loc[dfbox.neurons == 20].RMSE, \n",
    "        dfbox.loc[dfbox.neurons == 40].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 60].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 80].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 100].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 120].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 140].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 160].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 180].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 200].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [dfbox.loc[dfbox.neurons == 20].MAE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAPE = [dfbox.loc[dfbox.neurons == 20].MAPE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAPE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAPE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [dfbox.loc[dfbox.neurons == 20].RMSE, \n",
    "        dfbox.loc[dfbox.neurons == 40].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 60].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 80].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 100].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 120].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 140].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 160].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 180].RMSE,\n",
    "        dfbox.loc[dfbox.neurons == 200].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [dfbox.loc[dfbox.neurons == 20].MAE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('neuronios_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAPE = [dfbox.loc[dfbox.neurons == 20].MAPE, \n",
    "        dfbox.loc[dfbox.neurons == 40].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 60].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 80].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 100].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 120].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 140].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 160].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 180].MAPE,\n",
    "        dfbox.loc[dfbox.neurons == 200].MAPE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(MAPE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [20,40,60,80,100,120,140,160,180,200])\n",
    "plt.xlabel('Quantidade de neurônios')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Avaliação da variação de neurônios na camada oculta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.layers == 2].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 3].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 4].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 5].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.layers == 2].MAE,\n",
    "        dfbox.loc[dfbox.layers == 3].MAE,\n",
    "        dfbox.loc[dfbox.layers == 4].MAE,\n",
    "        dfbox.loc[dfbox.layers == 5].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.layers == 2].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 3].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 4].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 5].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.layers == 2].MAE,\n",
    "        dfbox.loc[dfbox.layers == 3].MAE,\n",
    "        dfbox.loc[dfbox.layers == 4].MAE,\n",
    "        dfbox.loc[dfbox.layers == 5].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.layers == 2].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 3].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 4].RMSE,\n",
    "        dfbox.loc[dfbox.layers == 5].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('camadas_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.layers == 2].MAE,\n",
    "        dfbox.loc[dfbox.layers == 3].MAE,\n",
    "        dfbox.loc[dfbox.layers == 4].MAE,\n",
    "        dfbox.loc[dfbox.layers == 5].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xticks([1, 2, 3, 4], [2,3,4,5])\n",
    "plt.xlabel('Quantidade de camadas ocultas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de camadas ocultas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('derivacao_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 2].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 3].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 4].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('derivacao_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 2].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 3].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 4].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('derivacao_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 2].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 3].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 4].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('derivacao_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 2].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 3].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 4].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('derivacao_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 2].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 3].RMSE,\n",
    "        dfbox.loc[dfbox.n_features == 4].RMSE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbox = pd.read_csv('derivacao_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.n_features == 1].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 2].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 3].MAE,\n",
    "        dfbox.loc[dfbox.n_features == 4].MAE\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de features')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.windows == 1].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 2].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 3].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 4].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 5].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_Temp.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.windows == 1].MAE,\n",
    "        dfbox.loc[dfbox.windows == 2].MAE,\n",
    "        dfbox.loc[dfbox.windows == 3].MAE,\n",
    "        dfbox.loc[dfbox.windows == 4].MAE,\n",
    "        dfbox.loc[dfbox.windows == 5].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.windows == 1].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 2].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 3].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 4].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 5].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_OD.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.windows == 1].MAE,\n",
    "        dfbox.loc[dfbox.windows == 2].MAE,\n",
    "        dfbox.loc[dfbox.windows == 3].MAE,\n",
    "        dfbox.loc[dfbox.windows == 4].MAE,\n",
    "        dfbox.loc[dfbox.windows == 5].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "RMSE = [\n",
    "        dfbox.loc[dfbox.windows == 1].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 2].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 3].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 4].RMSE,\n",
    "        dfbox.loc[dfbox.windows == 5].RMSE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfbox = pd.read_csv('janelas_PH.csv')\n",
    "dfbox = dfbox.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "\n",
    "MAE = [\n",
    "        dfbox.loc[dfbox.windows == 1].MAE,\n",
    "        dfbox.loc[dfbox.windows == 2].MAE,\n",
    "        dfbox.loc[dfbox.windows == 3].MAE,\n",
    "        dfbox.loc[dfbox.windows == 4].MAE,\n",
    "        dfbox.loc[dfbox.windows == 5].MAE,\n",
    "       ]\n",
    "\n",
    "plt.boxplot(RMSE, medianprops={\"linewidth\": 2})\n",
    "plt.xlabel('Quantidade de janelas')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Avaliação da variação de janelas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trieno Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['Temp']\n",
    "column_y = 'Temp'\n",
    "window = 1\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_mlp = abs(y_test - y_pred)\n",
    "erro_baseline = baseline_error('Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.ks_2samp(erro_mlp, erro_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.kdeplot(np.array(erro_mlp), bw=0.5, label='MLP')\n",
    "sns.kdeplot(np.array(erro_baseline), bw=0.5, label='baseline')\n",
    "plt.xlabel('Erro')\n",
    "plt.ylabel('Densidade')\n",
    "plt.title('Densidade do erro das predições de temperatura')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trieno OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['OD']\n",
    "column_y = 'OD'\n",
    "window = 1\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180,180,180,180,180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_mlp = y_test - y_pred\n",
    "erro_baseline = baseline_error('OD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.ks_2samp(erro_mlp, erro_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.kdeplot(np.array(erro_mlp), bw=0.5, label='MLP')\n",
    "sns.kdeplot(np.array(erro_baseline), bw=0.5, label='baseline')\n",
    "plt.xlabel('Erro')\n",
    "plt.ylabel('Densidade')\n",
    "plt.title('Densidade do erro das predições de OD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trieno PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['PH', 'PH_40', 'PH_50', 'PH_60']\n",
    "column_y = 'PH'\n",
    "window = 4\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180,180,180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_mlp = abs(y_test - y_pred)\n",
    "erro_baseline = baseline_error('PH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.ks_2samp(erro_mlp, erro_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13.7, 8.27))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.kdeplot(np.array(erro_mlp), bw=0.5, label='MLP')\n",
    "sns.kdeplot(np.array(erro_baseline), bw=0.5, label='baseline')\n",
    "plt.xlabel('Erro')\n",
    "plt.ylabel('Densidade')\n",
    "plt.title('Densidade do erro das predições de PH')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de anomalia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['Temp']\n",
    "column_y = 'Temp'\n",
    "window = 1\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "anomaly = pd.DataFrame()\n",
    "anomaly['y'] = np.concatenate([y_train, y_pred])\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "outliers_fraction = float(.1)\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(anomaly.y.values.reshape(-1,1))\n",
    "dt = pd.DataFrame(np_scaled)\n",
    "\n",
    "model = IsolationForest(n_estimators=100, contamination=outliers_fraction)\n",
    "model.fit(dt[:len(y_train)])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "append = [1]*len(y_train)\n",
    "x = model.predict(dt[len(y_train):])\n",
    "prd = np.concatenate([append, x])\n",
    "\n",
    "data['anomaly'] = prd    \n",
    "a = data.loc[data['anomaly'] == -1, ['y']]\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(data[['y']][:len(y_train)], color='#069AF3', linewidth=3.0, label='Valores do sensor')\n",
    "ax.plot(data[['y']][len(y_train):], color='#F97306', linewidth=3.0, label='Valores da predição')\n",
    "ax.scatter(a.index, a['y'], s= 100.0, color='black', label='Anomalia')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['OD']\n",
    "column_y = 'OD'\n",
    "window = 1\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180,180,180,180,180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "anomaly = pd.DataFrame()\n",
    "anomaly['y'] = np.concatenate([y_train, y_pred])\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "outliers_fraction = float(.1)\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(anomaly.y.values.reshape(-1,1))\n",
    "dt = pd.DataFrame(np_scaled)\n",
    "\n",
    "model = IsolationForest(n_estimators=100, contamination=outliers_fraction)\n",
    "model.fit(dt[:len(y_train)])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "append = [1]*len(y_train)\n",
    "x = model.predict(dt[len(y_train):])\n",
    "prd = np.concatenate([append, x])\n",
    "\n",
    "data['anomaly'] = prd    \n",
    "a = data.loc[data['anomaly'] == -1, ['y']]\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(data[['y']][:len(y_train)], color='#069AF3', linewidth=3.0, label='Valores do sensor')\n",
    "ax.plot(data[['y']][len(y_train):], color='#F97306', linewidth=3.0, label='Valores da predição')\n",
    "ax.scatter(a.index, a['y'], s= 100.0, color='black', label='Anomalia')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['PH', 'PH_40', 'PH_50', 'PH_60']\n",
    "column_y = 'PH'\n",
    "window = 4\n",
    "train_size = 0.7\n",
    "shift_prediction = 6\n",
    "result = pd.read_csv('dataset_preprocessado.csv', sep=',')\n",
    "result = result.drop(['Unnamed: 0'], axis=1)\n",
    "result\n",
    "data = window_all(result[column].reset_index(drop=True), window, column_y)\n",
    "data = data.dropna()\n",
    "\n",
    "shift_prediction *= -1\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y'].shift(periods=shift_prediction)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data[:shift_prediction]\n",
    "data = data.astype('float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_size)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(180,180,180), max_iter=1000, solver='adam',\n",
    "                         validation_fraction=0.1,  verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "M = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "anomaly = pd.DataFrame()\n",
    "anomaly['y'] = np.concatenate([y_train, y_pred])\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "outliers_fraction = float(.1)\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(anomaly.y.values.reshape(-1,1))\n",
    "dt = pd.DataFrame(np_scaled)\n",
    "\n",
    "model = IsolationForest(n_estimators=100, contamination=outliers_fraction)\n",
    "model.fit(dt[:len(y_train)])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "append = [1]*len(y_train)\n",
    "x = model.predict(dt[len(y_train):])\n",
    "prd = np.concatenate([append, x])\n",
    "\n",
    "data['anomaly'] = prd    \n",
    "a = data.loc[data['anomaly'] == -1, ['y']]\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(data[['y']][:len(y_train)], color='#069AF3', linewidth=3.0, label='Valores do sensor')\n",
    "ax.plot(data[['y']][len(y_train):], color='#F97306', linewidth=3.0, label='Valores da predição')\n",
    "ax.scatter(a.index, a['y'], s= 100.0, color='black', label='Anomalia')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
